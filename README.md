# Non-Intrusive-Attendance-Marking-System-using-AI
The project that we worked on this summer internship falls in the domain of research in IoT (Internet of Things). Initially, the mentor asked us to find real-life problems, which we would attempt to solve by using the tools of Information Technology. We were allowed to discuss and work in a group of three. We picked the problem of devising an attendance monitoring system, which would mark the presence of the students in a big room, in a non-intrusive manner using image recognition, for e.g. an auditorium or our collegeâ€™s lecture theatre. Our project was divided into two phases, which would be illustrated in the subsequent passages.  The first phase involved doing a literature survey on the tools and technologies through various authentic research papers and the existing libraries, which would enable us to devise a backend structure for our project. We, then developed a flowchart, which comprised of two modules of processes, through which the procedure would pass through. The first module involves the initial training of a machine learning based classifier by training it with the various images of a specific person. The second module involves the testing part in the real environment, which involves face detection and face recognition. A camera would take the frames/image of a live audience. Then, these frames would be pre-processed (involves grey-scaling and image resizing) for achieving better performance in the subsequent face detection module. The face-detection algorithm would detect all the faces present in the frame, and would crop the detected faces, and would pass them to the face recognition classifier for testing. The classifier would classify the cropped images and would mark the attendance accordingly. The libraries used for face-detection were that of OpenCV, and a convolutional neural network was trained for the image recognition part. The libraries which were used for training the convolutional neural network was Keras.  The second phase involved the implementation part, where we had to gather the data for training the neural network, and find out the parameters of the image, for which we are getting better accuracy performance. We trained the neural network with the images of about 64 students, with about 20 images per student, covering different angles and brightness levels. We trained the network with 70 percent of the image corpus, and used the remaining 30 percent for testing. We got an accuracy of 93 percent. For testing the face detection part, we took a video of a classroom of about 40 students. Then, we generated frames from the video and passed it to the face detection algorithm. We extrapolated that the accuracy of an individual frame was not that high, but if we consider all the detected members in all the frames, we are covering almost every student. Hence, considering multiple frames for testing is crucial to get a high detection accuracy.  We are currently trying to figure out the camera and its mounting position, which would be conducive for the algorithm, to give us accurate results.
